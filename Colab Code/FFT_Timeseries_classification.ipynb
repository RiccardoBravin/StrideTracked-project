{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mUDfVcJkH8S"
      },
      "source": [
        "Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWb36dJFgklZ",
        "outputId": "a71281ad-b8ef-459f-9f04-2e87a07aca71"
      },
      "outputs": [],
      "source": [
        "#ALL IMPORTS\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statistics import mode\n",
        "import csv\n",
        "import os\n",
        "import random\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "from math import cos, sin\n",
        "from scipy.interpolate import interp1d\n",
        "\n",
        "!mkdir ./newData\n",
        "!mkdir ./KNNtrain\n",
        "!mkdir ./SVMtest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCF55SNu8VzU"
      },
      "source": [
        "##Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSZs--nky2KM",
        "outputId": "914fb4e3-e483-424e-9830-45a48e101775"
      },
      "outputs": [],
      "source": [
        "#create container for file data\n",
        "def load_data(directory =  './'):\n",
        "  data = []\n",
        "  # iterate over files in that directory\n",
        "  for filename in os.listdir(directory):\n",
        "      f = os.path.join(directory, filename)\n",
        "      # checking if it is a file\n",
        "      if os.path.isfile(f) and f.endswith(\".csv\"):\n",
        "        with open(f) as csvfile:\n",
        "          print(\"reading file: \", f);\n",
        "          csv_f = csv.reader(csvfile, delimiter = \"\\t\")\n",
        "          data = data + [row for row in csv_f]\n",
        "\n",
        "  return data\n",
        "\n",
        "print(\"Training data loading\")\n",
        "data = load_data(\"./\")\n",
        "\n",
        "print(\"Testing data loading\")\n",
        "newData = load_data(\"./newData\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SY8rvOuMWPd"
      },
      "outputs": [],
      "source": [
        "#custom normalization\n",
        "def mean_std_norm(data):\n",
        "  media = np.mean(np.asarray(data).astype(float),0)\n",
        "  stdev = np.std(np.asarray(data).astype(float),0)\n",
        "\n",
        "  print(\"Media = \", media)\n",
        "  print(\"Stdev = \", stdev)\n",
        "\n",
        "  for i in range(len(data)):\n",
        "    for j in range(6):\n",
        "      data[i][j] = (float(data[i][j]) - media[j]) / stdev[j]\n",
        "\n",
        "#min-max normalization alternative (DO THIS)\n",
        "def min_max_norm(data):\n",
        "  for i in range(len(data)):\n",
        "    for j in range(6):\n",
        "      data[i][j] = float(data[i][j]) / 16384\n",
        "\n",
        "#post split normalization sample by sample\n",
        "def samp_norm(X):\n",
        "  for x in X:\n",
        "    media = np.mean(x,0)\n",
        "    stdev = np.std(x,0)\n",
        "\n",
        "    for i in range(len(x)):\n",
        "      for j in range(6):\n",
        "        x[i][j] = (float(x[i][j]) - media[j]) / stdev[j]\n",
        "  return X\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGqUbv5ZVuXc"
      },
      "outputs": [],
      "source": [
        "min_max_norm(data)\n",
        "min_max_norm(newData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "235FqWLbFDaR"
      },
      "outputs": [],
      "source": [
        "#Decide windows size and overlapping\n",
        "def split_XY(data, window_size = 500, overlap = 0):\n",
        "  #creating train set data\n",
        "  X = []\n",
        "  Y = []\n",
        "  for i in range(0, len(data)-window_size, int(window_size*(1-overlap))):\n",
        "    X.append([x[0:6] for x in data[i:i+window_size]])\n",
        "    Y.append(mode([int(y[6]) for y in data[i:i+window_size]]))\n",
        "\n",
        "  #convertion of values from string to integers\n",
        "  X = np.array(X).astype(float)\n",
        "  Y = np.array(Y).astype(int)\n",
        "\n",
        "  return X,Y\n",
        "\n",
        "X,Y = split_XY(data, 512, 0.3)\n",
        "X_new,Y_new = split_XY(newData, 512, 0.3)\n",
        "\n",
        "classes = len(np.unique(Y))\n",
        "\n",
        "del data, newData"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jto1iK787-en"
      },
      "source": [
        "###Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHI1rAppgQ7Z"
      },
      "outputs": [],
      "source": [
        "def randrot(X, ang = 0.4):\n",
        "  a = np.random.uniform(-ang,ang)\n",
        "  b = np.random.uniform(-ang,ang)\n",
        "  c = np.random.uniform(-ang,ang)\n",
        "\n",
        "  rot = [ [cos(a)*cos(b),     cos(a)*sin(b)*sin(c)-sin(a)*cos(c),     cos(a)*sin(b)*cos(c)+sin(a)*sin(c)],\n",
        "          [sin(a)*cos(b),     sin(a)*sin(b)*sin(c)+cos(a)*cos(c),     sin(a)*sin(b)*cos(c)-cos(a)*sin(c)],\n",
        "          [-sin(b),           cos(b)*sin(c),                          cos(b)*cos(c)                     ] ]\n",
        "\n",
        "  rot = np.array(rot)\n",
        "\n",
        "  for i in range(0,len(X)):\n",
        "    X[i][:3] = np.matmul(rot, X[i][:3])\n",
        "\n",
        "  return X\n",
        "\n",
        "\n",
        "def const_scaling(X, sigma=1):\n",
        "    scalingFactor = np.random.normal(loc=1.2, scale=sigma, size=(1,X.shape[1])) # shape=(1,3)\n",
        "    myNoise = np.matmul(np.ones((X.shape[0],1)), scalingFactor)\n",
        "    return (X*myNoise).tolist()\n",
        "\n",
        "def noise_add(X, sigma=0.0008):\n",
        "    myNoise = np.random.normal(loc=0, scale=sigma, size=X.shape)\n",
        "    return (X+myNoise).tolist()\n",
        "\n",
        "def obfuscation(X):\n",
        "  rnd_sz = random.randint(10,50)\n",
        "  rnd_pos = random.randint(0,len(X)-rnd_sz)\n",
        "\n",
        "  for i in range(rnd_pos, rnd_pos+rnd_sz):\n",
        "    for j in range(0,len(X[0])):\n",
        "      X[i][j] = 0\n",
        "\n",
        "  return X.tolist()\n",
        "\n",
        "def curve_scaling(X, sigma = 0.3, sz = 8):\n",
        "  noise = np.random.normal(loc=1, scale=sigma, size=(sz));\n",
        "\n",
        "  x = np.linspace(0, X.shape[0], sz)\n",
        "  noise = interp1d(x, noise, kind = 'quadratic')\n",
        "  scalingFactor = noise(range(0,X.shape[0]))\n",
        "\n",
        "  res = []\n",
        "  for x in np.transpose(x_val):\n",
        "    res.append(x*scalingFactor)\n",
        "\n",
        "  return np.transpose(res).tolist()\n",
        "\n",
        "def shift_values(X):\n",
        "  #shift value\n",
        "  val = random.randint(40,len(X)-40)\n",
        "  X = np.roll(X, val, 0)\n",
        "  return X.tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AvIf-Qnb_72",
        "outputId": "a252248c-3e51-4bf6-8e8c-506e51eb9be8"
      },
      "outputs": [],
      "source": [
        "#augment balancing classes (using the vector rotation)\n",
        "balanced = True\n",
        "\n",
        "x_aug = X.tolist()\n",
        "y_aug = Y.tolist()\n",
        "\n",
        "_, classes_count = np.unique(y_aug,return_counts=True)\n",
        "max_class = np.max(classes_count)\n",
        "\n",
        "class_num = 0\n",
        "for cc in classes_count:\n",
        "  indices = np.where(Y == class_num)[0]\n",
        "\n",
        "  while cc < max_class :\n",
        "    rnd_pos = random.randint(0, len(indices)-1)\n",
        "    rnd_pos = indices[rnd_pos]\n",
        "\n",
        "    x_val = np.array(x_aug[rnd_pos])\n",
        "    x_aug.append(randrot(x_val, 0.2))\n",
        "    y_aug.append(y_aug[rnd_pos])\n",
        "\n",
        "    cc=cc+1\n",
        "\n",
        "  class_num = class_num + 1\n",
        "\n",
        "_, classes_count = np.unique(y_aug,return_counts=True)\n",
        "print(classes_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTYHFFGluCfS"
      },
      "outputs": [],
      "source": [
        "size_multiplier = 4\n",
        "try: #needed to check if balancing of classes was performed\n",
        "    balanced;\n",
        "except NameError:\n",
        "  x_aug = X.tolist()\n",
        "  y_aug = Y.tolist()\n",
        "\n",
        "start_sz = len(x_aug)\n",
        "\n",
        "while (len(x_aug) < start_sz * size_multiplier):\n",
        "\n",
        "  for i in range(1):\n",
        "    #augmentation 1 (random rotation)\n",
        "    rnd_pos = random.randint(0, len(x_aug)-1)\n",
        "    x_val = np.array(x_aug[rnd_pos])\n",
        "    x_aug.append(randrot(x_val, 0.3))\n",
        "    y_aug.append(y_aug[rnd_pos])\n",
        "\n",
        "  #augmentation 2 (random noise)\n",
        "  rnd_pos = random.randint(0, len(x_aug)-1)\n",
        "  x_val = np.array(x_aug[rnd_pos])\n",
        "  x_aug.append(noise_add(x_val))\n",
        "  y_aug.append(y_aug[rnd_pos])\n",
        "\n",
        "  #augmentation 3 (random scaling)\n",
        "  rnd_pos = random.randint(0, len(x_aug)-1)\n",
        "  x_val = np.array(x_aug[rnd_pos])\n",
        "  x_aug.append(const_scaling(x_val))\n",
        "  y_aug.append(y_aug[rnd_pos])\n",
        "\n",
        "  #augmentation 5 (random shift to right)\n",
        "  rnd_pos = random.randint(0, len(x_aug)-1)\n",
        "  x_val = np.array(x_aug[rnd_pos])\n",
        "  x_aug.append(shift_values(x_val))\n",
        "  y_aug.append(y_aug[rnd_pos])\n",
        "\n",
        "\n",
        "\n",
        "x_train = np.array(x_aug)\n",
        "y_train = np.array(y_aug)\n",
        "\n",
        "del x_aug\n",
        "del y_aug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROrnBxQPUyHI"
      },
      "outputs": [],
      "source": [
        "#testing aug\n",
        "rnd_pos = 3000\n",
        "x_val = np.array(x_train[rnd_pos])\n",
        "# plt.plot(random_scaling(x_val,5))\n",
        "\n",
        "res = curve_scaling(x_val)\n",
        "\n",
        "sos, axis = plt.subplots(2)\n",
        "axis[0].plot(x_val)\n",
        "axis[1].plot(res)\n",
        "sos.suptitle(y_train[rnd_pos])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hs671lRZ6bMb",
        "outputId": "475e996b-b30e-44dc-ca8c-81fd93489461"
      },
      "outputs": [],
      "source": [
        "#check number of samples per label\n",
        "for i in range(10):\n",
        "  print(\"Count of \", i, \" labels: \", np.count_nonzero(y_train == i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euSFfCKwykqO"
      },
      "outputs": [],
      "source": [
        "#check last eight inserted augmentations\n",
        "fig = plt.figure(figsize=(15,6))\n",
        "for ii in range(8):\n",
        "    ax = fig.add_subplot(2,4,ii+1)\n",
        "    ax.plot(x_train[-ii])\n",
        "    plt.title(\"label = \" + str(y_train[-ii]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9JbEjdFzt1_"
      },
      "source": [
        "###FFT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcgbfVkkZPkH"
      },
      "outputs": [],
      "source": [
        "#FFT of sample\n",
        "def samp_fft(X):\n",
        "  trans = []\n",
        "  for x in X:\n",
        "    trans.append(np.absolute(np.fft.rfft(x, axis = 0)[1:])) #tolto valore trasformata in f=0. Prendo solo ampiezza (rimuovo fase)\n",
        "  return trans\n",
        "\n",
        "x_train = np.array(samp_fft(x_train))\n",
        "X_new =  np.array(samp_fft(X_new))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IoHMUYfzVTh"
      },
      "outputs": [],
      "source": [
        "#fft augmentation\n",
        "x_aug = []\n",
        "y_aug = []\n",
        "start_sz = len(x_train)\n",
        "increment = 0.5\n",
        "\n",
        "for i in range(0,int(start_sz*increment)):\n",
        "  #aug 1\n",
        "  rnd_pos = random.randint(0, start_sz-1)\n",
        "  x_val = x_train[rnd_pos] + np.random.normal(0.08, 0.06)\n",
        "  x_aug.append(x_val)\n",
        "  y_aug.append(y_train[rnd_pos])\n",
        "\n",
        "  #aug 2\n",
        "  rnd_pos = random.randint(0, start_sz-1)\n",
        "  x_val = x_train[rnd_pos]\n",
        "  x_aug.append(curve_scaling(x_val))\n",
        "  y_aug.append(y_train[rnd_pos])\n",
        "\n",
        "\n",
        "x_aug = np.array(x_aug)\n",
        "y_aug = np.array(y_aug)\n",
        "\n",
        "x_train = np.append(x_train, x_aug, 0)\n",
        "y_train = np.append(y_train, y_aug, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "aj9LkTNRwsou",
        "outputId": "393d620a-e729-493b-aeba-74bdabcd11a0"
      },
      "outputs": [],
      "source": [
        "#check last eight inserted augmentations\n",
        "fig = plt.figure(figsize=(15,6))\n",
        "for ii in range(8):\n",
        "    ax = fig.add_subplot(2,4,ii+1)\n",
        "    ax.plot(x_train[-ii])\n",
        "    plt.title(\"label = \" + str(y_train[-ii]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYviylB2Q0o8",
        "outputId": "7d58c4a0-3693-472c-b7d9-b74b9f08adc3"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "  print(\"Count of \", i, \" labels: \", np.count_nonzero(y_train == i))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNEnx5kihM_d"
      },
      "source": [
        "##Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ks5Pb-VWCigo",
        "outputId": "60c2dbe9-7c7b-49a9-cad6-4995a9cf9e48"
      },
      "outputs": [],
      "source": [
        "#@title Conv2D FOR FFT\n",
        "model = keras.Sequential(\n",
        "  [\n",
        "    keras.layers.Input((x_train.shape[1],x_train.shape[2],1)),\n",
        "    keras.layers.Conv2D(filters=128, kernel_size=(20,1), strides = (5,1), activation=\"relu\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "    keras.layers.Conv2D(filters=16, kernel_size=(10,3), strides = (2,3), activation=\"relu\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "    keras.layers.Conv2D(filters=128, kernel_size=(8,2), strides = (3,1), activation=\"relu\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "    keras.layers.GlobalAveragePooling2D(),\n",
        "    keras.layers.Dense(classes, activation=\"softmax\")\n",
        "  ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o39-OjvrhTDJ"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEbIziOrdFxc",
        "outputId": "9bf250d7-bc46-4bcf-b574-53e6772ecafe"
      },
      "outputs": [],
      "source": [
        "epochs = 300\n",
        "batch_size = 128\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        \"best_model.h5\", save_best_only=True, monitor=\"val_loss\"\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\", factor=0.5, patience=10, min_lr=0.00005\n",
        "    ),\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=25, verbose=1),\n",
        "]\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.05)\n",
        "\n",
        "#ADD OR REMOVE \"SPARSE\" FOR ONEHOT ENCODING OR NOT\n",
        "model.compile(\n",
        "    optimizer = opt,\n",
        "    loss = \"sparse_categorical_crossentropy\",\n",
        "    metrics = [\"sparse_categorical_accuracy\"],\n",
        ")\n",
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        "    validation_data = (X_new, Y_new),\n",
        "    verbose=1,\n",
        "    shuffle = True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o8b0_Wqfi80"
      },
      "source": [
        "##Evaluation of results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "oBMJHogifnci",
        "outputId": "c31b2323-69a0-4db0-8551-5c7a622ce667"
      },
      "outputs": [],
      "source": [
        "#Plot the model's training and validation loss\n",
        "metric = \"sparse_categorical_accuracy\"\n",
        "plt.figure()\n",
        "plt.plot(history.history[metric])\n",
        "plt.plot(history.history[\"val_\" + metric])\n",
        "plt.title(\"model \" + metric)\n",
        "plt.ylabel(metric, fontsize=\"large\")\n",
        "plt.xlabel(\"epoch\", fontsize=\"large\")\n",
        "plt.legend([\"train\", \"val\"], loc=\"best\")\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "_iYmjNvMgr8W",
        "outputId": "93313e9d-edba-40b6-b1cc-4fd5218adf3e"
      },
      "outputs": [],
      "source": [
        "# CONFUSION MATRIX OF TRAININIG DATA\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "#predict labels of validation/test dataset\n",
        "predictions = model.predict(x_train);\n",
        "#print(predictions)\n",
        "predictions = np.argmax(predictions, axis = 1)\n",
        "\n",
        "\n",
        "#draw confusion matrix\n",
        "con_mat = tf.math.confusion_matrix(y_train, predictions).numpy()\n",
        "print(con_mat)\n",
        "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "\n",
        "classes_list = range(0,classes)\n",
        "con_mat_df = pd.DataFrame(con_mat_norm, index = classes_list, columns = classes_list)\n",
        "\n",
        "figure = plt.figure(figsize=(5, 4))\n",
        "\n",
        "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1O1t05ZfkbE",
        "outputId": "aa11a665-22f9-4ac1-d722-8f596723e520"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model(\"best_model.h5\")\n",
        "\n",
        "test_loss, test_acc = model.evaluate(X_new, Y_new)\n",
        "\n",
        "print(\"Test accuracy\", test_acc)\n",
        "print(\"Test loss\", test_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2n8h4GxWvBgm",
        "outputId": "e43c66da-b887-44f4-bdde-16fb7012fb75"
      },
      "outputs": [],
      "source": [
        "!pip install numpy==1.22.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "Bv-3wmmTv_ed",
        "outputId": "577a4de6-ff7f-49a5-8bb6-664080c77c0c"
      },
      "outputs": [],
      "source": [
        "#CONFUSION MATRIX WITH UNSEEN DATA\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "#predict labels of validation/test dataset\n",
        "predictions = model.predict(X_new);\n",
        "\n",
        "predictions = np.argmax(predictions, axis = 1)\n",
        "\n",
        "\n",
        "#draw confusion matrix\n",
        "con_mat = tf.math.confusion_matrix(Y_new, predictions).numpy()\n",
        "print(con_mat)\n",
        "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "\n",
        "classes_list = range(0,len(con_mat))\n",
        "con_mat_df = pd.DataFrame(con_mat_norm, index = classes_list, columns = classes_list)\n",
        "\n",
        "figure = plt.figure(figsize=(5, 4))\n",
        "\n",
        "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0sSiSv_XO4v"
      },
      "source": [
        "##Quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrbXCXCmXQ2Q"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model(\"best_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3eJm5D-X3SV",
        "outputId": "b73d32f8-23d7-43d3-8eb7-e6d1bd99dbf4"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "dataset_x = tf.data.Dataset.from_tensor_slices(x_train)\n",
        "\n",
        "def representative_dataset_gen():\n",
        "    for input_value in dataset_x.batch(1).take(100):\n",
        "        input_value = tf.expand_dims(input_value, axis=-1)  # only for CONV2 NN: Aggiungi una dimensione di canale\n",
        "        yield [tf.cast(input_value, tf.float32)]\n",
        "\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "del dataset_x\n",
        "\n",
        "open('q_model_2.tflite', 'wb').write(tflite_model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpJKqhJDjJHU",
        "outputId": "4f81ff98-8dea-40d0-b538-e70a79fdf691"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "open('q_model_1.tflite', 'wb').write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jxcjo4x2rl4L"
      },
      "outputs": [],
      "source": [
        "#Loading model\n",
        "def predict_q_model(filename, x_test):\n",
        "  interpreter = tf.lite.Interpreter(model_path=tflite_model_file)\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  #getting input specifics to pass later\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "\n",
        "  #changing type to ensure correct analization\n",
        "  test_vals = x_test.astype(np.float32)\n",
        "\n",
        "  predictions = []\n",
        "\n",
        "  tensorSize = np.append(list(test_vals.shape),1)\n",
        "  tensorSize[0] = 1\n",
        "\n",
        "  for i in tqdm(range(len(test_vals))):\n",
        "    interpreter.set_tensor(input_index, test_vals[i].reshape(tensorSize)) #this for conv2d\n",
        "    #interpreter.set_tensor(input_index, test_vals[i].reshape(1,500,6))  #this for conv1d\n",
        "    interpreter.invoke()\n",
        "    predictions.append(interpreter.get_tensor(output_index))\n",
        "\n",
        "  return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rrahS7qC8gI",
        "outputId": "65693b44-d1c9-4d1f-bd28-348088e26cac"
      },
      "outputs": [],
      "source": [
        "tflite_model_file = 'q_model_2.tflite' # Change the filename here for different models\n",
        "\n",
        "predictions = predict_q_model(tflite_model_file, X_new)\n",
        "\n",
        "score = 0\n",
        "for i in range(len(Y_new)):\n",
        "  prediction=np.argmax(predictions[i])\n",
        "  label = Y_new[i]\n",
        "  if prediction==label:\n",
        "    score=score+1\n",
        "\n",
        "print(\"\\nOut of\", len(Y_new), \"predictions, \" + str(score) + \" were correct\")\n",
        "print(\"Accuracy: \", score/len(Y_new))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leRHQogwU6kW"
      },
      "source": [
        "##SVM implementation with last CNN layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shjgIDRVV6Ef",
        "outputId": "8ec94082-b623-43c7-9f0e-40552df11244"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model(\"best_model.h5\")\n",
        "model.pop() # this will remove the last layer\n",
        "model.summary() # check the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qG5uvugJ7RvM",
        "outputId": "f816eaa0-d953-4cdc-a0df-697d259797e1"
      },
      "outputs": [],
      "source": [
        "\n",
        "svm_data = load_data(\"./KNNtrain\")\n",
        "min_max_norm(svm_data)\n",
        "\n",
        "svm_x_train, svm_y_train = split_XY(svm_data, 512, 0)\n",
        "svm_x_train = samp_fft(svm_x_train)\n",
        "svm_x_train = np.array(svm_x_train)\n",
        "\n",
        "svm_data = load_data(\"./SVMtest\")\n",
        "min_max_norm(svm_data)\n",
        "\n",
        "svm_x_test, svm_y_test = split_XY(svm_data, 512, 0)\n",
        "svm_x_test = samp_fft(svm_x_test)\n",
        "svm_x_test = np.array(svm_x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "XoFLCEXcjXpA",
        "outputId": "57428ed5-1467-40f7-abba-f1a6a62ddabf"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm, tree, ensemble, neighbors\n",
        "\n",
        "feature_mapping = model(svm_x_train)\n",
        "\n",
        "# clf = svm.SVC(gamma = 0.001)\n",
        "#clf = ensemble.RandomForestClassifier()\n",
        "clf = neighbors.KNeighborsClassifier()\n",
        "\n",
        "clf.fit(feature_mapping, svm_y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJGN5hOucZQJ",
        "outputId": "2528d061-4c56-4fa6-ce8b-a80644fdf841"
      },
      "outputs": [],
      "source": [
        "predCNN = model(svm_x_test)\n",
        "\n",
        "predSVM = clf.predict(predCNN)\n",
        "\n",
        "res = np.count_nonzero(svm_y_test == predSVM)\n",
        "\n",
        "print(\"The accuracy of the classifier is: \", res/len(predSVM)*100, \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "NJQ-aOjRokO6",
        "outputId": "51eea21f-b0fd-4dde-ff89-f6bd840a61b5"
      },
      "outputs": [],
      "source": [
        "#CONFUSION MATRIX WITH UNSEEN DATA\n",
        "\n",
        "#predict labels of validation/test dataset\n",
        "predictions = clf.predict(predCNN);\n",
        "\n",
        "#draw confusion matrix\n",
        "con_mat = tf.math.confusion_matrix(svm_y_test, predictions).numpy()\n",
        "print(con_mat)\n",
        "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "\n",
        "classes_list = range(0,10)\n",
        "con_mat_df = pd.DataFrame(con_mat_norm, index = classes_list, columns = classes_list)\n",
        "\n",
        "figure = plt.figure(figsize=(5, 4))\n",
        "\n",
        "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJrijt_FDYFh"
      },
      "source": [
        "#Quantization + SVM/tree/KNN\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PWyIuHSDXK0",
        "outputId": "19bb3853-1bc0-4a21-b04f-54807c9ea60a"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model(\"best_model.h5\")\n",
        "model.pop()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_WusshADnIc",
        "outputId": "26524e5b-b310-4585-93a2-3fa180bc0f79"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "dataset_x = tf.data.Dataset.from_tensor_slices(x_train)\n",
        "\n",
        "def representative_dataset_gen():\n",
        "    for input_value in dataset_x.batch(1).take(100):\n",
        "        input_value = tf.expand_dims(input_value, axis=-1)  # only for CONV2 NN: Aggiungi una dimensione di canale\n",
        "        yield [tf.cast(input_value, tf.float32)]\n",
        "\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "del dataset_x\n",
        "open('q_model_2.tflite', 'wb').write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhVVPY3gCRMo",
        "outputId": "7448f12c-4a90-496c-f32d-68b2129d2464"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "open('q_model_1.tflite', 'wb').write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aY2ha_WtmEo",
        "outputId": "7c98afd9-833c-4c89-f7f0-efa2d670bff4"
      },
      "outputs": [],
      "source": [
        "!mkdir ./newData\n",
        "!mkdir ./KNNtrain\n",
        "!mkdir ./SVMtest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AsHiHiuDqYN",
        "outputId": "ffe72608-3091-4768-b124-add5b055e239"
      },
      "outputs": [],
      "source": [
        "\n",
        "svm_data = load_data(\"./KNNtrain\")\n",
        "min_max_norm(svm_data)\n",
        "\n",
        "svm_x_train, svm_y_train = split_XY(svm_data, 512, 0)\n",
        "svm_x_train = samp_fft(svm_x_train)\n",
        "svm_x_train = np.array(svm_x_train)\n",
        "\n",
        "svm_data = load_data(\"./SVMtest\")\n",
        "min_max_norm(svm_data)\n",
        "\n",
        "svm_x_test, svm_y_test = split_XY(svm_data, 512, 0)\n",
        "svm_x_test = samp_fft(svm_x_test)\n",
        "svm_x_test = np.array(svm_x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "3NAx-XerEWBx",
        "outputId": "3cd67ffe-d693-452b-b89e-c855a2785a54"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm, tree, ensemble, neighbors\n",
        "\n",
        "tflite_model_file = 'q_model_2.tflite' # Change the filename here for different models\n",
        "\n",
        "feature_mapping = predict_q_model(\"q_model_2.tflite\", svm_x_train)\n",
        "feature_mapping = np.array(feature_mapping).squeeze()\n",
        "print(feature_mapping.shape);\n",
        "\n",
        "# clf = svm.SVC(gamma = 0.001)\n",
        "# clf = ensemble.RandomForestClassifier()\n",
        "clf = neighbors.KNeighborsClassifier()\n",
        "\n",
        "clf.fit(feature_mapping, svm_y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YweEG07EFNHt",
        "outputId": "abbcdd0c-c32d-4fb0-c914-9255bed06f5c"
      },
      "outputs": [],
      "source": [
        "predCNN = predict_q_model(\"q_model_2.tflite\", svm_x_test)\n",
        "print(len(predCNN));\n",
        "\n",
        "predCNN = np.array(predCNN).squeeze()\n",
        "print(predCNN.shape);\n",
        "predSVM = clf.predict(predCNN)\n",
        "\n",
        "res = np.count_nonzero(svm_y_test == predSVM)\n",
        "print(\"\\nThe accuracy of the SVM is: \", res/len(predSVM)*100, \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un8WWimDbPlb",
        "outputId": "0fbb4f7d-ef2c-4f10-c3ed-9b70db6f8b9f"
      },
      "outputs": [],
      "source": [
        "#check structure tflite model\n",
        "# Carica il modello TFLite\n",
        "interpreterCheck = tf.lite.Interpreter(model_path=\"q_model_2.tflite\")\n",
        "interpreterCheck.allocate_tensors()\n",
        "\n",
        "# Ottieni dettagli del modello\n",
        "input_details = interpreterCheck.get_input_details()\n",
        "output_details = interpreterCheck.get_output_details()\n",
        "\n",
        "# Stampa dettagli del modello\n",
        "print(\"Input details:\")\n",
        "print(input_details)\n",
        "print(\"\\nOutput details:\")\n",
        "print(output_details)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJxr--ZSGQVN",
        "outputId": "0752c9e5-7388-45a5-f63f-5106f2770a8c"
      },
      "outputs": [],
      "source": [
        "!pip install -U micromlgen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "hGWZ7xciFqF6",
        "outputId": "367c249b-8bd0-4007-8b57-97ea7f8c4e30"
      },
      "outputs": [],
      "source": [
        "from micromlgen import port\n",
        "\n",
        "c_code = port(clf)\n",
        "\n",
        "with open('classifier.h', 'w') as file:\n",
        "  file.write(c_code)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dFWbea9anUz"
      },
      "source": [
        "# TFLite->TFMicro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njz_vZira5NG",
        "outputId": "3ca2f9d9-358d-458e-d630-3301763d7d43"
      },
      "outputs": [],
      "source": [
        "!apt-get update && apt-get -qq install xxd\n",
        "\n",
        "MODEL_TFLITE = '/content/q_model_2.tflite'\n",
        "MODEL_TFLITE_MICRO = 'q_model_2_2_new.cc'\n",
        "!xxd -i {MODEL_TFLITE} > {MODEL_TFLITE_MICRO}\n",
        "#REPLACE_TEXT = MODEL_TFLITE.replace('/', '_').replace('.', '_')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSE-AJCiHNV9",
        "outputId": "04a10f93-e856-44fa-c773-090526a5103d"
      },
      "outputs": [],
      "source": [
        "#saving model not quantized\n",
        "!zip -r ./model.zip ./saved_model"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
